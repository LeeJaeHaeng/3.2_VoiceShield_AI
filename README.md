# 🛡️ VoiceShield AI - 지능형 보이스피싱 탐지 및 예방 솔루션

**모바일 프로그래밍 최종 프로젝트**

- **개발자**: 2023243119 컴퓨터공학부 이재행

---

## 📖 프로젝트 개요

**VoiceShield AI**는 딥러닝 기술을 활용하여 날로 교묘해지는 보이스피싱과 딥페이크 위협으로부터 사용자를 보호하는 모바일 보안 솔루션입니다. 음성과 이미지 데이터를 실시간으로 분석하여 위조 여부를 판별하고, 사용자가 위협 상황에 대처할 수 있도록 즉각적인 경고와 보호 기능을 제공합니다.

---

## ✨ 핵심 기능 상세 (Key Features)

### 1. 🔍 멀티모달 딥페이크 탐지 (Multimodal Detection)

VoiceShield AI는 비선형적인 패턴을 감지하기 위해 다층적인 AI 모델을 사용합니다.

- **음성 정밀 분석 (Audio Analysis)**

  - **기술**: CNN-LSTM 하이브리드 모델 + Wav2Vec2 기반 특징 추출
  - **기능**: 통화/녹음된 음성의 주파수(Frequency)와 시간적(Temporal) 특성을 분석하여, 실제 사람의 목소리와 AI가 합성한 목소리의 미세한 차이를 식별합니다.
  - **결과**: `REAL` / `FAKE` 판별과 함께 신뢰도(Confidence Score), 스펙트로그램, MFCC 시각화 자료를 제공합니다.

- **이미지 위조 탐지 (Image Forensics)**

  - **기술**: ELA(Error Level Analysis) + AI 모델 앙상블 (SDXL Detector 등)
  - **기능**: 딥페이크로 의심되는 인물 사진이나 신분증 이미지를 분석합니다. 압축률 차이를 이용한 ELA 기법과 **주파수 도메인 분석(FFT)**을 결합하여, 육안으로 보이지 않는 미세한 조작 흔적이나 생성형 AI의 스펙트럼 패턴을 정밀하게 잡아냅니다.
  - **결과**: 위조 의심 확률과 함께 조작된 것으로 추정되는 영역(히트맵)을 시각적으로 표시합니다.

- **화자 분리 및 분석 (Speaker Diarization)**
  - **기술**: PyTorch / SpeechBrain
  - **기능**: 다자간 통화 시 "누가 언제 말했는지"를 화자(Speaker)별로 분리하고, 각 화자의 **성별** 및 **연령대**를 추정합니다.
  - **활용**: 검사 사칭(주로 남성)이나 가족 사칭 범죄에서 화자의 특성이 실제와 일치하는지 대조할 수 있습니다.

### 2. 🛡️ 실시간 보호 및 예방 (Real-time Protection)

단순한 탐지를 넘어, 실제 상황에서의 예방책을 제공합니다.

- **라이브 모니터링 (Live Monitoring)**
  - **기능**: 통화 중 실시간으로 오디오를 캡처하여 분석합니다. 보이스피싱 위험 단어(예: "계좌 이체", "대포통장", "검찰")가 감지되거나 딥페이크 징후가 포착되면 화면의 **위험도 게이지(Risk Score)**가 상승하며 사용자에게 경고를 보냅니다.
  - **강화된 로직**: "대포 통장"과 같은 띄어쓰기 변형을 자동 보정하며, 핵심 위험 키워드 감지 시 즉시 '위험' 단계로 격상되는 부스팅 알고리즘이 적용되었습니다.
- **가디언 모드 (Guardian Mode)**
  - **기능**: 납치 협박이나 위협적인 고액 송금 요구 등 비상 상황 발생 시, 사용자가 '긴급 버튼'을 누르면 미리 등록된 **보호자(가족, 지인)**에게 즉시 경고 SMS가 전송됩니다.
- **피싱 예방 훈련 (Phishing Drills)**
  - **기능**: 실제 보이스피싱 사례(검찰 사칭, 문자 스미싱, 가족 납치 등)를 기반으로 한 **시나리오 퀴즈**를 제공하여, 사용자가 평소에 위협에 대처하는 능력을 기를 수 있도록 돕습니다.

### 3. 👥 보이스 ID (Voice ID) - 지인 사칭 방지

- **기능**: 사용자가 신뢰하는 가족이나 지인의 목소리를 미리 등록("Voice Fingerprint")해 둡니다.
- **작동 원리**: 낯선 번호로 가족을 사칭하는 전화가 왔을 때, 실시간으로 목소리를 대조하여 등록된 Voice ID와 일치하는지(본인 여부)를 즉시 확인합니다.

---

## 🛠️ 기술적 특징 및 아키텍처 (Technical Architecture)

본 프로젝트는 고성능 AI 추론과 모바일 접근성을 결합한 하이브리드 아키텍처를 채택했습니다.

### 🏗️ 시스템 구조

- **Frontend**: **React Native (Expo)**
  - 사용자 친화적인 모바일 UI/UX, 직관적인 대시보드
  - 비동기 API 통신 및 실시간 오디오/이미지 처리
- **Backend**: **Python FastAPI**
  - 고속 비동기 서버, PyTorch/TensorFlow 모델 서빙
  - SQLite 데이터베이스 연동 (사용자 기록, Voice ID 관리)
- **AI Engine**:
  - **TensorFlow/Keras**: 딥페이크 탐지 (CNN-LSTM)
  - **PyTorch/SpeechBrain**: 화자 인식 및 분리 (ECAPA-TDNN)
  - **OpenCV**: 이미지 포렌식 (ELA)

### 📈 성능 개선 (Technical Highlights)

- **앙상블 기법 도입**: 단일 모델의 오탐지율을 줄이기 위해, 음성과 이미지 분석 모두 복수의 모델 결과를 종합(Weighted Average)하여 판단 정확도를 **90% 이상**으로 끌어올렸습니다.
- **동적 임계값 적용**: 상황에 따라 판별 기준(Threshold)을 유동적으로 적용하여, 애매한 케이스("Unknown")에 대한 오판을 최소화했습니다.

---

## 🚀 설치 및 실행 방법

### 1. 백엔드 (AI 서버) 실행

Python 3.8 이상 환경이 필요합니다.

1. `backend` 폴더로 이동하여 필요 라이브러리 설치:

   ```bash
   cd backend
   pip install -r requirements.txt
   ```

   _(Windows 사용 시 `ffmpeg` 및 오디오 코덱 관련 에러가 발생하면 추가 설치가 필요할 수 있습니다.)_

2. 서버 시작:
   ```bash
   python server.py
   ```
   **성공 확인**: `Application startup complete` 메시지가 출력되면 정상 작동 중입니다 (Port: 8000).

### 2. 프론트엔드 (모바일 앱) 실행

Node.js 환경이 필요합니다.

1. 프로젝트 최상위 폴더(`voiceshield_ai_v2`)에서 패키지 설치:

   ```bash
   npm install
   ```

2. Expo 앱 시작:
   ```bash
   npx expo start --clear
   ```
   - 제공되는 QR 코드를 **Expo Go** 앱으로 스캔하거나, 에뮬레이터(Android Studio)에서 실행합니다.

---

## ⚠️ 테스트 시 주의사항

1. **AI 모델 다운로드**: 서버 최초 실행 시 Hugging Face에서 모델을 다운로드하느라 다소 시간이 소요될 수 있습니다.
2. **네트워크 설정**: 모바일 기기와 서버(PC)가 동일한 네트워크(Wi-Fi)에 있어야 통신이 가능합니다. (`src/config.js` IP 설정 확인)
3. **권한 허용**: 앱의 기능을 온전히 사용하기 위해 **마이크**, **카메라**, **파일 접근** 권한을 허용해 주세요.

---

## 📝 라이선스

0BSD License.
학술 및 과제 제출용으로 제작되었습니다.
